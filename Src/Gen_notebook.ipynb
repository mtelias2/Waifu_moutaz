{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook is to try and implement waifu images from scratch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this training for spellbrush, goal is to recreate anime faces first using pytorch, then using JAX as well and finally try to use diffusion instead of GAN.\n",
    "\n",
    "<img src=\"https://i.imgur.com/6NMdO9u.png\">\n",
    "\n",
    "There are two neural networks: a Generator and a Discriminator. The generator generates a \"fake\" sample given a random vector/matrix, and the discriminator attempts to detect whether a given sample is \"real\" (picked from the training data) or \"fake\" (generated by the generator). Training happens in tandem: we train the discriminator for a few epochs, then train the generator for a few epochs, and repeat. This way both the generator and the discriminator get better at doing their jobs.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/NaKtJs0.png\">\n",
    "Anime Face Dataset\n",
    ", which consists of over 63,000 cropped anime faces:https://www.kaggle.com/splcher/starter-anime-face-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting basic setiing\n",
    "dataroot = \"~moutazelias/Desktop/Desktop/Github/Datasets/animefacedataset/\"          # Root directory for dataset\n",
    "Image_Size =64              # Number of workers for dataloader\n",
    "batch_size = 128            # Batch size during training\n",
    "lr = 0.0002                 # Learning rate for optimizers\n",
    "num_epochs=100              # Number of training epochs\n",
    "ngpu = 0                    # Number of GPUs available. Use 0 for CPU mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(Image_Size),\n",
    "                               transforms.CenterCrop(Image_Size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on (if i am using google colab or not)\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images.detach(), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, _ in dl:\n",
    "        show_images(images)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
